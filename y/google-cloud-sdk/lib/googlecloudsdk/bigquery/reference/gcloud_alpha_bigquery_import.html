<html devsite="">
<head>
<title>gcloud alpha bigquery import</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="project_path" value="/sdk/_project.yaml">
<meta name="book_path" value="/sdk/_book.yaml">
<!--
        THIS DOC IS GENERATED.  DO NOT EDIT.
        -->
<style>
  dd { margin-bottom: 1ex; }
  .hangingindent { padding-left: 1.5em; text-indent: -1.5em; }
</style>
</head>
<body><dl>
<section>
<dt>NAME</dt>
<dd>gcloud alpha bigquery import - import data from a specified source into a specified destination table</dd>
</section><section>
<dt>SYNOPSIS</dt>
<dd><pre>gcloud alpha bigquery import SOURCE DESTINATION_TABLE [--allow-jagged-rows] [--allow-quoted-newlines] [--async] [--encoding ENCODING; default="utf-8"] [--field-delimiter FIELD_DELIMITER; default=","] [--fingerprint-job-id] [--ignore-unknown-values] [--job-id JOB_ID] [--max-bad-records MAX_BAD_RECORDS] [--quote QUOTE; default="""] [--replace] [--schema SCHEMA] [--schema-file SCHEMA_FILE] [--skip-leading-rows SKIP_LEADING_ROWS] [--source-format SOURCE_FORMAT] [--status STATUS; default="periodic"] [GLOBAL-FLAG â€¦]</pre></dd>
</section><section>
<dt>DESCRIPTION</dt>
<dd>
<code>(ALPHA)</code> If the table does not exist, it is created. Otherwise, the imported data is
added to the table.</dd>
</section><section>
<dt>POSITIONAL ARGUMENTS</dt>
<dd><dl>
<dt class="hangingindent">
<code><var>SOURCE</var></code>
</dt>

<dd>
Either a path to a single local file containing CSV or JSON data, or a comma-separated list of URIs with the protocol gs:, specifying files in Google Storage.
</dd>


<dt>
<code><var>DESTINATION_TABLE</var></code>
</dt>

<dd>
The fully-qualified name of table into which data is to be imported.
</dd>

</dl></dd>
</section><section>
<dt>FLAGS</dt>
<dd><dl>
<dt>
<code>--allow-jagged-rows</code>
</dt>

<dd>
Allow missing trailing optional columns in CSV import data.
</dd>


<dt>
<code>--allow-quoted-newlines</code>
</dt>

<dd>
Allow quoted newlines in CSV import data.
</dd>


<dt>
<code>--async</code>
</dt>

<dd>
Create an asynchronous job to perform the import.
</dd>


<dt>
<code>--encoding</code> <code><var>ENCODING</var></code>; default="utf-8"
</dt>

<dd>
The character encoding used for the source data.
</dd>


<dt>
<code>--field-delimiter</code> <code><var>FIELD_DELIMITER</var></code>; default=","
</dt>

<dd>
The character that indicates the boundary between columns in CSV source data. " " and "tab" are accepted names for tab.
</dd>


<dt>
<code>--ignore-unknown-values</code>
</dt>

<dd>
Allow and ignore extra, unrecognized values in CSV or JSON import data.
</dd>


<dt>
<code>--job-id</code> <code><var>JOB_ID</var></code>
</dt>

<dd>
A unique job_id to use for the request. If this flag is not specified, a job_id will be generated automatically and displayed as the result of the command.
</dd>


<dt>
<code>--max-bad-records</code> <code><var>MAX_BAD_RECORDS</var></code>
</dt>

<dd>
Maximum number of bad records allowed before the entire job fails.
</dd>


<dt>
<code>--quote</code> <code><var>QUOTE</var></code>; default="""
</dt>

<dd>
Quote character to use to enclose records. Default is the double-quote character ("). To indicate no quote character at all, use an empty string.
</dd>


<dt>
<code>--replace</code>
</dt>

<dd>
Erase existing contents before loading new data.
</dd>


<dt>
<code>--schema</code> <code><var>SCHEMA</var></code>
</dt>

<dd>
A comma-separated list of entries of the form name[:type], where type defaults to string if not present, specifying field names and types for the destination table. Possible types are string, integer, float, boolean, record, and timestamp.
</dd>


<dt>
<code>--schema-file</code> <code><var>SCHEMA_FILE</var></code>
</dt>

<dd>
The name of a JSON file containing a single array object, each element of which is an object with properties name, type, and, optionally, mode, specifying a schema for the destination table. Possible types are string, integer, float, boolean, record, and timestamp.  Possible modes are NULLABLE, REQUIRED, and REPEATED.
</dd>


<dt>
<code>--skip-leading-rows</code> <code><var>SKIP_LEADING_ROWS</var></code>
</dt>

<dd>
The number of rows at the beginning of the source data to skip.
</dd>


<dt>
<code>--source-format</code> <code><var>SOURCE_FORMAT</var></code>
</dt>

<dd>
Format of source data.
</dd>


<dt>
<code>--status</code> <code><var>STATUS</var></code>; default="periodic"
</dt>

<dd>
Whether the status of the import job should be reported periodically, every time the status changes, or not at all.
</dd>

</dl></dd>
</section><section>
<dt>GROUP FLAGS</dt>
<dd><dl>
<dt>
<code>--fingerprint-job-id</code>
</dt>

<dd>
Whether to use a job id that is derived from a fingerprint of the job configuration.
</dd>

</dl></dd>
</section><section>
<dt>GLOBAL FLAGS</dt>
<dd>Run <code>$ <a href="../../">gcloud</a> help</code> for a description of flags available to
all commands.</dd>
</section><section>
<dt>EXAMPLES</dt>
<dd>To import data from csv with given schema specified in json file, run:</dd>
<dd><pre>$ <A href="../../alpha/bigquery/import">gcloud alpha bigquery import</A> ds/new_tbl ./info.csv \
    --schema ./info_schema.json</pre></dd>
<dd>To import data located on cloud storage, run:</dd>
<dd><pre>$ <A href="../../alpha/bigquery/import">gcloud alpha bigquery import</A> ds/new_tbl gs://mybucket/info.csv \
    --schema-file ./info_schema.json</pre></dd>
<dd>To import data with command line specified schema, run:</dd>
<dd><pre>$ <A href="../../alpha/bigquery/import">gcloud alpha bigquery import</A> ds/small gs://mybucket/small.csv \
    --schema name:integer,value:string</pre></dd>
<dd>To import data with default field string type, run:</dd>
<dd><pre>$ <A href="../../alpha/bigquery/import">gcloud alpha bigquery import</A> ds/small gs://mybucket/small.csv \
    --schema field1,field2,field3</pre></dd>
</section><section>
<dt>NOTES</dt>
<dd>This command is in the Google Cloud SDK <code>bigquery</code> component. See
<a href="/sdk/gcloud/#gcloud.components">installing components</a>
if it is not installed.</dd>
<dd>This command is currently in ALPHA and may change without notice.</dd>
</section>
</dl></body>
</html>

